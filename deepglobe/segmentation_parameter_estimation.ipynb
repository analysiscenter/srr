{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор архитектуры модели для сегментации типов ландшафта по данным аэрофотосъемки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Задача](#Задача)\n",
    "* [Исследуемые параметры](#Исследуемые-параметры)\n",
    "* [Измеряемые характеристики](#Измеряемые-характеристики)\n",
    "* [Описание исследования](#Описание-исследования)\n",
    "* [Результат исследования](#Результат-исследования)\n",
    "* [Вывод](#Вывод)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучить влияние параметров UNet на качество модели и выбрать оптимальные значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуемые параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество фильров в блоках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Измеряемые характеристики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика IoU на тестовой части датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорты библиотек и вспомогательных скриптов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from srr.batchflow import FilesIndex, Dataset, Pipeline, F, V, B, C, R, P\n",
    "from srr.batchflow.models.tf import UNet\n",
    "from srr.batchflow.research import Research, Results, Option, Grid\n",
    "\n",
    "from srr import AerialBatch\n",
    "from srr.core.utils import get_origs, ce_dice_loss, make_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция для работы с масками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask classes \n",
    "# 0 Unknown\n",
    "# 1 Water\n",
    "# 2 Forest land\n",
    "# 3 Urban land\n",
    "# 5 Rangeland\n",
    "# 6 Agriculture land\n",
    "# 7 Barren land\n",
    "\n",
    "make_mask = partial(make_mask, classes=(0,1,2,3,5,6,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию потерь:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = FilesIndex(path='../ignore/deepglobe/train/*.jpg')\n",
    "ads = Dataset(ind, AerialBatch)\n",
    "ads.split(0.8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'initial_block/inputs': 'images',\n",
    "    'inputs': dict(images={'shape': (256,256,3)}, \n",
    "                   masks={'name':'targets',\n",
    "                          'shape': (256,256,7)}),\n",
    "    'filters': C('filters'),\n",
    "    'head/num_classes': 7,\n",
    "    'loss': ce_dice_loss,\n",
    "    'optimizer': 'Adam',\n",
    "    'output': ['proba']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание пайплайнов для обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterations: 16050.\n",
      "Test after each 1500 iterations.\n"
     ]
    }
   ],
   "source": [
    "n_reps = 4\n",
    "batch_size = 8\n",
    "n_epochs = 200\n",
    "n_iters = int(n_epochs * (len(ads.train) / batch_size))\n",
    "iters_to_test = 1500\n",
    "itt = \"%{}\".format(iters_to_test)\n",
    "\n",
    "print(\"Total number of iterations: {}.\\nTest after each {} iterations.\".format(n_iters, iters_to_test))\n",
    "\n",
    "folder = '../ignore/research/UNet_segmentation_result_' + 'test'#datetime.now().strftime(format='%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_shape = (256, 256)\n",
    "\n",
    "train_template = (\n",
    "      Pipeline()\n",
    "      .load(ind, fmt='image', dst='images')\n",
    "      .load(ind, fmt='mask', dst='masks')\n",
    "      .resize(size=(1224, 1224), src=['images', 'masks'], dst=['images', 'masks'])\n",
    "      .apply_transform(get_origs, crop_shape, 1., src='masks', dst='origs')\n",
    "      .crop(shape=crop_shape, src=[('images', 'origs'), ('masks', 'origs')], dst=['images', 'masks'])\n",
    "      .rotate(P(R('randint', 0, 180)), src=['images', 'masks'], dst=['images', 'masks'], p=0.5)\n",
    "      .flip('lr', src=['images', 'masks'], dst=['images', 'masks'], p=0.5)\n",
    "      .enhance(factor=P(R('uniform', 0.5, 1.5)))\n",
    "      .pil_convert(src='images', dst='images', p=C('grayscale'))\n",
    "      .to_array(src=['images', 'masks'], dst=['images', 'masks'])\n",
    "      .apply_transform(make_mask, src='masks', dst='masks')\n",
    "      .init_variable('loss', init_on_each_run=list)\n",
    "      .init_model('dynamic', UNet, 'unet', model_config)\n",
    "      .train_model('unet', images=B('images'), targets=B('masks'),\n",
    "                      fetches='loss', save_to=V('loss'), mode='w')\n",
    ").run(batch_size, n_epochs=n_epochs, shuffle=True, lazy=True, drop_last=True)\n",
    "\n",
    "test_template = (\n",
    "      Pipeline()    \n",
    "      .load(ind, fmt='image', dst='images')\n",
    "      .load(ind, fmt='mask', dst='masks')\n",
    "      .resize(size=(1224, 1224), src=['images', 'masks'], dst=['images', 'masks'])\n",
    "      .apply_transform(get_origs, crop_shape, 1., src='masks', dst='origs')\n",
    "      .crop(shape=crop_shape, src=[('images', 'origs'), ('masks', 'origs')], dst=['images', 'masks'])\n",
    "      .pil_convert(src='images', dst='images', p=C('grayscale'))\n",
    "      .to_array(src=['images', 'masks'], dst=['images', 'masks'])\n",
    "      .apply_transform(make_mask, src='masks', dst='masks')\n",
    "      .init_variable('predictions', init_on_each_run=list)\n",
    "      .init_variable('metrics', init_on_each_run=None)\n",
    "      .import_model('unet', C('import_from'))\n",
    "      .predict_model('unet', images=B('images'), targets=B('masks'),\n",
    "                   fetches=['proba'], save_to=[V('predictions')], mode='w')\n",
    "      .gather_metrics('segmentation', axis=-1, targets=B('masks'), predictions=V('predictions'),\n",
    "                      fmt='proba', save_to=V('metrics'), mode='u')\n",
    ").run(batch_size, n_epochs=1, lazy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание варьируемых параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = Option('grayscale', [0, 1])\n",
    "\n",
    "filter_opts = Option('filters', [[8, 16, 32],\n",
    "#                                  [32, 64, 128], [128, 256, 512],\n",
    "#                                  [16, 32, 64, 128], [32, 64, 128, 256], [64, 128, 256, 512],\n",
    "#                                  [8, 16, 32, 64, 128], [32, 64, 128, 256, 512],\n",
    "                                 [8, 16, 32, 64, 128, 256, 512]])\n",
    "\n",
    "opts = filter_opts * gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание параметров эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ppl = (train_template << ads.train)\n",
    "test_ppl = (test_template << ads.test)\n",
    "\n",
    "research = (Research()\n",
    "            .pipeline(train_ppl, name='train', variables='loss')\n",
    "            .pipeline(test_ppl, variables='metrics', execute=itt, dump=itt,\n",
    "                      name='test', run=True, import_from='train')\n",
    "            .grid(opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research ../ignore/research/UNet_segmentation_result_test is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributor has 16 jobs with 16050 iterations. Totally: 256800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256800/256800 [00:09<00:00, 27168.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<srr.batchflow.research.research.Research at 0x7f416501ca90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research.run(n_reps=n_reps, n_iters=n_iters, workers=8, name=folder, progress_bar=True, gpu=[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты исследования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = '../ignore/research/UNet_segmentation_result_201903291534/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Results(path=folder).load(use_alias=True, cv=['None'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in df.config.unique():\n",
    "    print(\"Model configuration: \\n{}\".format(conf))\n",
    "    for rep in df.repetition.unique():\n",
    "        condition = (df.name=='test')&(df.config==conf)&(df.repetition==rep)\n",
    "        values = df[condition]['metrics'].apply(lambda x: x.evaluate('iou')).values\n",
    "        iters = np.arange(len(values)) * iters_to_test\n",
    "        plt.plot(iters, values)\n",
    "        plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in df.config.unique():\n",
    "    print(\"Model configuration: \\n{}\".format(conf))\n",
    "    for rep in df.repetition.unique():\n",
    "        condition = (df.name=='train')&(df.config==conf)&(df.repetition==rep)\n",
    "        loss_ep = np.array(np.split(df[condition]['loss'], n_epochs))\n",
    "        loss_mean = np.mean(loss_ep, axis=-1)\n",
    "        plt.plot(loss_mean)\n",
    "        plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in df.config.unique():\n",
    "    print(\"Model configuration: \\n{}\".format(conf))\n",
    "    values = []\n",
    "    for rep in df.repetition.unique():\n",
    "        condition = (df.name=='test')&(df.config==conf)&(df.repetition==rep)\n",
    "        values.append(df[condition]['metrics'].apply(lambda x: x.evaluate('iou')).values)\n",
    "        iters = np.arange(len(values[0])) * iters_to_test\n",
    "    values = np.array(values)\n",
    "    plt.plot(iters, np.mean(values, axis=0))\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf in df.config.unique():\n",
    "    print(\"Model configuration: \\n{}\".format(conf))\n",
    "    loss_mean = []\n",
    "    for rep in df.repetition.unique():\n",
    "        condition = (df.name=='train')&(df.config==conf)&(df.repetition==rep)\n",
    "        loss_ep = np.array(np.split(df[condition]['loss'], n_epochs))\n",
    "        loss_mean.append(np.mean(loss_ep, axis=-1))\n",
    "    loss_mean = np.mean(loss_mean, 0)\n",
    "    plt.plot(loss_mean)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
